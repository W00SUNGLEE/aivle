{"cells":[{"cell_type":"markdown","metadata":{"id":"52e1f0fb"},"source":["# 안녕하세요^^ \n","# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n","* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n","* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n","* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!"]},{"cell_type":"markdown","metadata":{"id":"nUXBrxPDiFd9"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"orwgQqTkEW0C"},"source":["# __[Study] 2. 구글 오픈 이미지 데이터 셋 활용 YOLOv5 ObjectDetection__\n","- Google Open Image Data?\u003cbr\u003e\n","구글이 머신러닝을 위해 2016년에 공개한 이미지에 주석이 달린 데이터셋으로 약 190만개에 전문 라벨러들이 라벨링을 검수한 이미지들을 포함하고 있습니다. 데이터셋은 V1부터 계속 업데이트 되어 2020년 2월 기준으로 가장 최신 버전인 V6버전까지 공개되었습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"ZPJwlsgmDmMQ"},"source":["## 0. 환경 설정하기"]},{"cell_type":"markdown","metadata":{"id":"Y5OZR2I9sfVq"},"source":["### 1) 구글 드라이브 연결하기\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30085,"status":"ok","timestamp":1666586212063,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"opm0PySCseDD","outputId":"6fc1db58-bbb5-4309-a019-92372638e427"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# 코랩 사용 시 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"bzQ5ZM05swzJ"},"source":["### 2) 경로 확인하기\n","- \"WORK_SPACE\" 에 본인 작업 경로 작성 후 실행(구글 드라이브 최상위에 압축해제 시 그대로 실행. 수정 X).\u003cbr\u003e"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1666586218088,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"I66_jbFEsuz9"},"outputs":[],"source":["# ROOT_PATH 확인 \n","import os\n","\n","# 구글 드라이브 내 프로젝트 압축해제된 영역 (구글 드라이브 최상위에 압축해제하였을 경우 수정하지 않으셔도 됩니다.)\n","WORK_SPACE = \"\"\n","\n","if os.getcwd() == '/content' :\n","  # 구글 드라이브 사용 시 \n","  ROOT_PATH = \"/content/drive/MyDrive\" + \"/안전모탐지\"\n","else :\n","  ROOT_PATH = os.path.abspath('..')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xB7iJVzd7eHh"},"source":["### 3) YOLOv5파일 다운로드 및 설치\n","\n","![install](https://github.com/DrKAI/CV/raw/main/UltraLytics_manual/yolov5_install.png)\n","\n","[Install Page](https://github.com/ultralytics/yolov5)\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2548,"status":"ok","timestamp":1666586225554,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"E8ClcNk0cU7A","outputId":"951389f9-a74f-4eea-f7b4-126df0b243da"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 14379, done.\u001b[K\n","remote: Total 14379 (delta 0), reused 0 (delta 0), pack-reused 14379\u001b[K\n","Receiving objects: 100% (14379/14379), 13.32 MiB | 18.07 MiB/s, done.\n","Resolving deltas: 100% (9955/9955), done.\n"]}],"source":["# UltraLytics git에서 복사하기\n","%cd /content\n","!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5482,"status":"ok","timestamp":1666586242210,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"_0O_N_2VctaW","outputId":"fd35b6c0-316a-444d-db72-0358fc28e2f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib\u003e=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python\u003e=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n","Requirement already satisfied: torch\u003e=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n","Requirement already satisfied: torchvision\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n","Requirement already satisfied: tqdm\u003e=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n","Requirement already satisfied: tensorboard\u003e=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n","Requirement already satisfied: pandas\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n","Requirement already satisfied: seaborn\u003e=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.4.8)\n","Collecting thop\u003e=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 10)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 10)) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 10)) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 10)) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.7.0-\u003e-r requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (0.37.1)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.0.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (0.6.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.8.1)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.49.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.35.0)\n","Requirement already satisfied: protobuf\u003c3.20,\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (3.17.3)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.3.0)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=1.1.4-\u003e-r requirements.txt (line 23)) (2022.4)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (4.9)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (4.2.4)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (4.13.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (3.9.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 18)) (3.2.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit\u003c2.1.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (2.0.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (2.6.1)\n","Collecting jedi\u003e=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (4.8.0)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (5.1.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython-\u003e-r requirements.txt (line 41)) (0.2.0)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi\u003e=0.10-\u003eipython-\u003e-r requirements.txt (line 41)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit\u003c2.1.0,\u003e=2.0.0-\u003eipython-\u003e-r requirements.txt (line 41)) (0.2.5)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect-\u003eipython-\u003e-r requirements.txt (line 41)) (0.7.0)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"]}],"source":["# yolov5 폴더 이동 및 requirements.txt 내부 패키지 설치\n","%cd /content/yolov5\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"av7r3quaDmMV"},"source":["### 4) 라이브러리 불러오기\n","필요시 추가 라이브러리는 설치해서 사용하세요."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666586249283,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"ZYimZcrODmMW","scrolled":false},"outputs":[],"source":["# 필요 라이브러리 불러오기.\n","import glob\n","import yaml\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"49648b6d"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"vocational-animal"},"source":["## 1. 데이터 불러오기\n","* OIDv4_ToolKit을 활용하여 Google Open Dataset 다운로드하기\n","\u003e ① Google Open Dataset 검색\u003cbr\u003e\n","  https://storage.googleapis.com/openimages/web/index.html\u003cbr\u003e\n","  Google Open Image Dataset 특징 : COCO와 비슷하지만, 용량은 훨씬 많음.\u003cbr\u003e\n","\u003e ② OID Toolkit 설치\u003cbr\u003e\n","  https://github.com/EscVM/OIDv4_ToolKit/\u003cbr\u003e\n","  https://github.com/theAIGuysCode/OIDv4_ToolKit/\u003cbr\u003e \n","```# 코드로 형식 지정됨\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt\n","```\n","\u003e ③ OID Toolkit을 활용하여 Dataset 다운로드 하기\u003cbr\u003e\n","```# 코드로 형식 지정됨\n","!python main.py downloader --classes Apple Orange --type_csv validation\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"OTqROJ9xMyPk"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 1. OID Toolkit을 다운로드하고 설치하세요."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1666586404993,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"FgwGNwAR7KSd","outputId":"1c03c0da-0987-47b5-9828-9d35783d5eb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# 현재 경로 화인하기\n","%pwd\n","%cd /content"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":16774,"status":"ok","timestamp":1666586490424,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"W_YVEdsh2LL7","outputId":"cb1bfd43-b64d-482b-f740-9427a15cbd5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'OIDv4_ToolKit'...\n","remote: Enumerating objects: 444, done.\u001b[K\n","remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444\u001b[K\n","Receiving objects: 100% (444/444), 34.09 MiB | 21.63 MiB/s, done.\n","Resolving deltas: 100% (157/157), done.\n","/content/OIDv4_ToolKit\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Collecting awscli\n","  Downloading awscli-1.25.97-py3-none-any.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 14.2 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003e-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003e-r requirements.txt (line 1)) (2022.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003e-r requirements.txt (line 1)) (1.15.0)\n","Collecting docutils\u003c0.17,\u003e=0.10\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[K     |████████████████████████████████| 548 kB 70.9 MB/s \n","\u001b[?25hCollecting s3transfer\u003c0.7.0,\u003e=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.7 MB/s \n","\u001b[?25hCollecting colorama\u003c0.4.5,\u003e=0.2.5\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting botocore==1.27.96\n","  Downloading botocore-1.27.96-py3-none-any.whl (9.3 MB)\n","\u001b[K     |████████████████████████████████| 9.3 MB 58.7 MB/s \n","\u001b[?25hCollecting PyYAML\u003c5.5,\u003e=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 69.4 MB/s \n","\u001b[?25hCollecting rsa\u003c4.8,\u003e=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting jmespath\u003c2.0.0,\u003e=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting urllib3\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1\u003e=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa\u003c4.8,\u003e=3.1.2-\u003eawscli-\u003e-r requirements.txt (line 3)) (0.4.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9\n","    Uninstalling rsa-4.9:\n","      Successfully uninstalled rsa-4.9\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.17.1\n","    Uninstalling docutils-0.17.1:\n","      Successfully uninstalled docutils-0.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 awscli-1.25.97 botocore-1.27.96 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.6.0 urllib3-1.26.12\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{},"output_type":"display_data"}],"source":["# 실습해보세요\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"tgKkaBmH1kVf"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 2. OID Toolkit을 활용하여 Google Open Dataset 에서 'Helmet', 'Person' 키워드로 검색한 데이터 셋을 다운로드 하세요.\n","\u003e --classes : Helmet, Person\u003cbr\u003e\n","\u003e --multiclasses : 다양한 class의 이미지를 다른 폴더에 넣는게 아니라 하나의 폴더에 묶어서 다운로드\u003cbr\u003e\n","\u003e --limit : 카테고리당, 최대 이미지 수\u003cbr\u003e"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1666586610074,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"hSkbWUKsTXh8","outputId":"f9f84fad-e014-4bfa-bb5e-39340edd163a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.15\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1666586698388,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"7Q2jp5t-Tsvy","outputId":"a95e3fd3-e6d2-4595-cdb5-2582ee522d84"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/OIDv4_ToolKit'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["%pwd"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202270,"status":"ok","timestamp":1666587080559,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"BRgP4wKe1jkI","outputId":"15c9a837-9364-4326-e72b-3d5ba2833219"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","\r...72%, 0 MB, 82031 KB/s, 0 seconds passed\r...145%, 0 MB, 52509 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 1138 MB, 40426 KB/s, 28 seconds passed\n","\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 7608 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 100 images in train.\u001b[0m\n","100% 100/100 [00:44\u003c00:00,  2.27it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 248384 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 96 images in train.\u001b[0m\n","100% 96/96 [00:41\u003c00:00,  2.32it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 16 MB, 77204 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 274 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 50 images in validation.\u001b[0m\n","100% 50/50 [00:20\u003c00:00,  2.45it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 6436 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 50 images in validation.\u001b[0m\n","100% 50/50 [00:22\u003c00:00,  2.20it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n"]}],"source":["!python main.py downloader --classes Helmet Person --type_csv train --multiclasses 1 --limit 100 -y\n","!python main.py downloader --classes Helmet Person --type_csv validation --multiclasses 1 --limit 50 -y"]},{"cell_type":"markdown","metadata":{"id":"3d25c0a2"},"source":["## 2. 모델링을 위한 Train Data(학습)와 Validation 데이터(검증) 확인\n","* 다운로드 완료된 데이터는 '/content/OID/OIDv4_ToolKit/OID/Dataset/\"에 위치하고 있습니다.\n","* [Tip] 폴더 구조를 불러올 때 쓰는 glob 라이브러리 활용\n","\n","\u003e [방법1] \n","\u003e\u003e DATA_PATH = \"/content/OIDv4_ToolKit/OID/Dataset\" \u003cbr\u003e\n","\u003e\u003e TRAIN_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/train\"\u003cbr\u003e\n","\u003e\u003e VALIDATION_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/validation\"\u003cbr\u003e"]},{"cell_type":"markdown","metadata":{"id":"uKsfTWsUNUrj"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 3. Train Data와 Test Data 이미지 개수를 확인하세요."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1666587783435,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"bRY9DKHnX1V4"},"outputs":[],"source":["DATA_PATH = \"/content/OIDv4_ToolKit/OID/Dataset\"\n","TRAIN_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/train\"\n","VALIDATION_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/validation\""]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":544,"status":"ok","timestamp":1666587764612,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"KfH7TeTQ-jC6"},"outputs":[],"source":["# 라이브러리 불러오기\n","import glob"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1666588007394,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"500TMbwkNoYV"},"outputs":[],"source":["# 실습해보세요.\n","train_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train/*/*.jpg\")\n","validation_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation/*/*.jpg\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666588007918,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"hCGtY3ypqROn","outputId":"8a75e8f6-c713-4bda-cac5-4834b33e78e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습 데이터(이미지) 개수 : 196\n","검증 데이터(이미지) 개수 : 100\n"]}],"source":["print(\"학습 데이터(이미지) 개수 : \" + str(len(train_image_list)))\n","print(\"검증 데이터(이미지) 개수 : \" + str(len(validation_image_list)))"]},{"cell_type":"markdown","metadata":{"id":"RU_w0oUlKwpU"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 4. label 디렉토리 내 .txt 파일을 확인하여 YOlOv5 학습을 위한 label .txt 파일과의 차이를 확인하세요.  \u003cbr\u003e \n","\u003e [Tip] 리눅스에서 파일 내용을 확인할 때는 cat 명령어를 사용합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1666588153222,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"jTKotm04Kryj","outputId":"18589940-cf40-4443-e7d2-628ba8890b6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Helmet 733.036544 101.21122299999999 946.838528 260.25658599999997\n","Person 0.0 20.884879 577.104896 732.573656\n","Person 212.194304 147.8 419.566592 713.295363\n","Person 577.104896 101.21122299999999 1022.39232 737.393414\n"]}],"source":["# 실습해보세요.\n","train_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train/Helmet_Person/Label/*.txt\")\n","%cat \"{train_label_list[0]}\""]},{"cell_type":"markdown","metadata":{"id":"ooJza-Gx2kaD"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 5. \"/OIDv4_Toolkit\" 내 \"classes.txt\" 파일의 class 구성을 Helmet, Person으로 수정하고,\u003cbr\u003e\n","\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;YOLO 학습을 위해 center_x, center_t, Dw, Dh 의 값을 정규화 후 다시 생성된 label .txt 파일을 확인해보세요.\u003cbr\u003e \n","\u003e [Tip] 정규화는 covert_annotaion.py 모듈을 활용하시면 진행 가능합니다.\u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp; Python 모듈은 !python ooooooo.py command를 입력하면 실행 가능합니다. \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp; 새로 생성된 label .txt 파일은 이미지가 있는 경로(\"/Helmet_Person\")에 함께 생성됩니다."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666588164174,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"zvIkivou_DFP","outputId":"606f9e8a-8892-4c54-ecf6-c8689c273352"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/OIDv4_ToolKit\n"]}],"source":["# 현재 경로 확인\n","%pwd\n","%cd /content/OIDv4_ToolKit/"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13663,"status":"ok","timestamp":1666588465775,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"wGVKlPB92j3a","outputId":"ef93d724-23ef-43cb-9141-b2c5d2dc48be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Currently in subdirectory: validation\n","Converting annotations for class:  Helmet_Person\n","100% 100/100 [00:04\u003c00:00, 24.72it/s]\n","Currently in subdirectory: train\n","Converting annotations for class:  Helmet_Person\n","100% 196/196 [00:08\u003c00:00, 22.20it/s]\n"]}],"source":["# 실습해보세요.\n","!python convert_annotations.py"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1666588565179,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"FBC5up3s1vMN","outputId":"054e306d-ca22-4e99-d442-fbd51eede96e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.819371625 0.24385821786197562 0.20879099999999995 0.21521699999999996\n","1 0.28125 0.5086398903924222 0.563579 0.9630430000000001\n","1 0.3078069375 0.581596752368065 0.20251200000000003 0.765217\n","1 0.780375875 0.5672682313937754 0.434851 0.860869\n"]}],"source":["train_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train//Helmet_Person/*.txt\")\n","validation_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation//Helmet_Person/*.txt\")\n","%cat \"{train_label_list[0]}\""]},{"cell_type":"markdown","metadata":{"id":"dDJfSRaPBtPy"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 6. annotaion 정보를 convert 완료된 데이터를 복사/이동하여 YOLOv5 학습을 위한 디렉토리 구조로 변경합니다.\u003cbr\u003e\n","* YOLOv5 모델링을 위해서 데이터 디렉터리 구조는 다음과 같이 만들어야 합니다.\u003cbr\u003e\n","- 데이터 디렉터리 구조 \u003cbr\u003e\n","\u003e data ─ train\u0026ensp;┐ \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;├ images \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;├ labels \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp; ─ validation\u0026ensp; ┐ \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026ensp;├ images \u003cbr\u003e\n","\u003e \u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026emsp;\u0026ensp;├ labels \u003cbr\u003e"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1666588694829,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"hpFtBcC-BnRI"},"outputs":[],"source":["# DATA_PATH 지정하기\n","DATA_PATH = \"/content/data\"\n","TRAIN_PATH = DATA_PATH + \"/train\"\n","VALIDATION_PATH = DATA_PATH + \"/validation\"\n","\n","import shutil\n","\n","def file_copy(file_list, file_path):\n","  if not os.path.exists(file_path):\n","    os.makedirs(file_path)  \n","  for f in file_list:\n","    shutil.move(f, file_path)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":552,"status":"ok","timestamp":1666588739877,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"saORJr0OBY-l"},"outputs":[],"source":["file_copy(train_label_list, TRAIN_PATH + \"/labels\")\n","file_copy(train_image_list, TRAIN_PATH + \"/images\")\n","file_copy(validation_label_list, VALIDATION_PATH + \"/labels\")\n","file_copy(validation_image_list, VALIDATION_PATH + \"/images\")"]},{"cell_type":"markdown","metadata":{"id":"HzSe0SSnoKXM"},"source":["## 3. Yaml 파일 생성하기\n","* Yaml이란? xml과 json 포맷과 같이 타 시스템 간에 데이터를 주고받을 때 약속된 포맷(규칙)이 정의되어있는 파일 형식\u003cbr\u003e\n","https://abluesnake.tistory.com/128\u003cbr\u003e"]},{"cell_type":"markdown","metadata":{"id":"IiRgiZV4oKXM"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 6. train, validation 이미지 경로를 txt 파일로 저장하기 \n","- yolov5 학습을 위해 data.yaml 파일 내 \n","train, val의 값을 이미지 파일들의 경로를 저장한 .txt 파일로 변경이 필요합니다.\n","```\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","      f.write('\\n'.join(train_image_list) + '\\n')\n","```\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":367,"status":"ok","timestamp":1666589107460,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"Bvq8D4QboM68"},"outputs":[],"source":["# 실습해보세요\n","train_image_list = glob.glob(TRAIN_PATH + \"/*/*.jpg\")\n","validation_image_list = glob.glob(VALIDATION_PATH + \"/*/*.jpg\")\n","\n","\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","    f.write('\\n'.join(train_image_list) + '\\n')\n","\n","with open(DATA_PATH + '/validation.txt', 'w') as f:\n","    f.write('\\n'.join(validation_image_list) + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"bHhUf2Y4obSV"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 7. \"data.yaml\" 파일을 생성하고 내 라벨 클래스들과 경로를 입력해주세요.\n","* data.yaml 파일은 딕셔너리 형태로 되어 있습니다.\n","\u003e - 데이터 경로 \u003cbr\u003e\n","\u003e train : DATA_PATH + '/train.txt'\u003cbr\u003e\n","\u003e val : DATA_PATH + '/validation.txt'\u003cbr\u003e\n","\u003e - 클래스 수 \u003cbr\u003e\n","\u003e nc: 2\u003cbr\u003e\n","\u003e - 클래스 이름 \u003cbr\u003e\n","\u003e names: ['Helmet', 'Person'] \u003cbr\u003e\n","```\n","data = {\n","              'train' : ,\n","              'val' : ,\n","              'nc' : ,\n","              'names' : [  ]       \n","}\n","```\n","* yaml 파일은 dump() 메소드로 쓰기 가능합니다.\n","```\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","        yaml.dump(data, f)\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKq1-6sEF9xc"},"outputs":[],"source":["# 라이브러리 불러오기\n","import yaml"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666589233715,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"eE8D2BB6roG7","outputId":"419c72b8-16f9-4eeb-cd9b-c9d3e4ed3bb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': '/content/data/train.txt', 'val': '/content/data/validation.txt', 'nc': 2, 'names': ['Helmet', 'Person']}\n"]}],"source":["# 실습해보세요.\n","data = {\n","          'train' : DATA_PATH + '/train.txt',\n","          'val' : DATA_PATH + '/validation.txt',\n","          'nc' : 2 ,\n","          'names' : [ 'Helmet', 'Person' ]       \n","}\n","\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","  yaml.dump(data, f)\n","\n","print(data)"]},{"cell_type":"markdown","metadata":{"id":"f0oi8s0DLcFX"},"source":["## 4. Yolov5 를 이용한 모델 학습\n","\u003e https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data/\u003cbr\u003e\n","\u003e ○ [Command] \n","```# 코드로 형식 지정됨\n"," !python train.py --img 640 --epochs 3 --data coco.yaml --weights yolov5n.pt --batch 128 \n","                                                                  yolov5s            64\n","                                                                  yolov5m            40\n","                                                                  yolov5l            24\n","                                                                  yolov5x            16\n","```\n","\n","\u003e ○ [Properties]\n","\u003e\u003e --img: 입력 이미지 크기 \u003cbr\u003e\n","\u003e\u003e --batch: 배치 크기 \u003cbr\u003e\n","\u003e\u003e --epochs: 학습 epoch 수 \u003cbr\u003e\n","\u003e\u003e --data: data.yaml 파일 경로 \u003cbr\u003e\n","\u003e\u003e --cfg: 모델 구성 지정 \u003cbr\u003e\n","\u003e\u003e --weights: 가중치에 대한 사용자 정의 경로를 지정\u003cbr\u003e\n","\u003e\u003e --name: 모델이 저장 될 폴더 이름 \u003cbr\u003e\n","\u003e\u003e --nosave: 최종 체크포인트만 저장\u003cbr\u003e\n","\u003e\u003e --cache: 더 빠른 학습을 위해 이미지를 캐시\u003cbr\u003e\n","\n","\u003e ○ [Select Model]\u003cbr\u003e\n","\u003e\u003cimg src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\" width=\"640px\"\u003e"]},{"cell_type":"markdown","metadata":{"id":"szLs-keis-q7"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 8. Yolov5s(small) 모델을 활용하여 학습하세요.\n","\u003e img size : 416 \u003cbr\u003e\n","\u003e batch size : 16 \u003cbr\u003e\n","\u003e epochs : 5 \u003cbr\u003e\n","\u003e data : /content/data/data.yaml \u003cbr\u003e\n","\u003e weights : yolov5s.pt \u003cbr\u003e\n","\u003e name : OID_helmet_data_detection \u003cbr\u003e"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1666589450433,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"GLWAsKIMTaMp","outputId":"d69c1642-87e7-4c17-f9a3-21eae75bec03"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n"]}],"source":["# 실행 경로 이동\n","%pwd\n","%cd /content/yolov5"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118142,"status":"ok","timestamp":1666589570467,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"dgqhwjxeLItu","outputId":"732c324e-c23c-4a0f-c45c-724122aabdc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=OID_helmet_data_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"requests\u003e=2.23.0\" \"torchvision\u003e=0.8.1\" \"tensorboard\u003e=2.4.1\" not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: torchvision\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: tensorboard\u003e=2.4.1 in /usr/local/lib/python3.7/dist-packages (2.9.1)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0) (2022.9.24)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.23.0) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision\u003e=0.8.1) (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision\u003e=0.8.1) (4.1.1)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision\u003e=0.8.1) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision\u003e=0.8.1) (1.21.6)\n","Requirement already satisfied: protobuf\u003c3.20,\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (3.17.3)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (0.6.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (1.35.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (1.8.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (57.4.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (1.3.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (0.4.6)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (1.0.1)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (1.49.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.4.1) (0.37.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1) (4.2.4)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1) (1.15.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1) (4.7.2)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1) (4.13.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1) (3.9.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1) (0.4.8)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1) (3.2.1)\n","Installing collected packages: urllib3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.12\n","    Uninstalling urllib3-1.26.12:\n","      Successfully uninstalled urllib3-1.26.12\n","Successfully installed urllib3-1.25.11\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m 3 packages updated per /content/yolov5/requirements.txt\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv5 🚀 v6.2-205-geef9057 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00\u003c00:00, 37.6MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00\u003c00:00, 219MB/s]\n","\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/train' images and labels...196 found, 0 missing, 0 empty, 0 corrupt: 100% 196/196 [00:00\u003c00:00, 1943.54it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/validation' images and labels...100 found, 0 missing, 0 empty, 0 corrupt: 100% 100/100 [00:00\u003c00:00, 775.04it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.16 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/OID_helmet_data_detection/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/OID_helmet_data_detection\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/4      1.71G     0.1188    0.03621    0.02933         57        416: 100% 13/13 [00:10\u003c00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05\u003c00:00,  1.26s/it]\n","                   all        100        277    0.00389      0.372    0.00379    0.00103\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/4       2.1G     0.1061    0.04237     0.0275         22        416: 100% 13/13 [00:08\u003c00:00,  1.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03\u003c00:00,  1.30it/s]\n","                   all        100        277     0.0171     0.0354     0.0154    0.00327\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        2/4       2.1G    0.09699    0.04885    0.02471         29        416: 100% 13/13 [00:08\u003c00:00,  1.57it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02\u003c00:00,  1.49it/s]\n","                   all        100        277     0.0895     0.0905     0.0383     0.0131\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        3/4       2.1G    0.08654    0.04805     0.0225         24        416: 100% 13/13 [00:08\u003c00:00,  1.46it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02\u003c00:00,  1.51it/s]\n","                   all        100        277      0.102      0.106     0.0667     0.0284\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        4/4       2.1G    0.08205    0.05039     0.0207         29        416: 100% 13/13 [00:08\u003c00:00,  1.53it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02\u003c00:00,  1.48it/s]\n","                   all        100        277      0.615      0.116     0.0751     0.0283\n","\n","5 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/train/OID_helmet_data_detection/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/OID_helmet_data_detection/weights/best.pt, 14.3MB\n","\n","Validating runs/train/OID_helmet_data_detection/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03\u003c00:00,  1.32it/s]\n","                   all        100        277      0.613      0.113     0.0751     0.0283\n","                Helmet        100         78          1          0     0.0114    0.00359\n","                Person        100        199      0.227      0.226      0.139      0.053\n","Results saved to \u001b[1mruns/train/OID_helmet_data_detection\u001b[0m\n"]}],"source":["# 실습해보세요.\n","!python train.py --img 416 --batch 16 --epochs 5 --data /content/data/data.yaml --weights yolov5s.pt --name OID_helmet_data_detection"]},{"cell_type":"markdown","metadata":{"id":"d3G--l-Xf8ZG"},"source":["## 5. 모델 성능 평가\n","\u003e Yolo에서는 모델의 성능(정확도)를 Mean Average Precision(mAP)를 통해 확인합니다. \u003cbr\u003e\n","mAP가 높을수록 정확하고, 작을수록 부정확합니다. \u003cbr\u003e\n","\u003e AP를 계산할 때, precision-recall,IoU 와 연관이 있습니다. \u003cbr\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"iCKM0MCGe0NQ"},"source":["## 6. Test 데이터 추론하기 \n","* 해당 결과는 runs/detect/exp/ 위치에 저장됩니다.\n","\u003e ○ [Command] \n","``` # 코드로 형식 지정됨\n","!python detect.py --source 0  # webcam\n","                           img.jpg  # image\n","                           vid.mp4  # video\n","                           screen  # screenshot\n","                           path/  # directory\n","                           'path/*.jpg'  # glob\n","                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n","                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","```\n","\u003e ○ [Properties] \n","\u003e\u003e -- source : test 데이터(이미지, 영상 파일 혹은 폴더) 경로 \u003cbr\u003e\n","\u003e\u003e -- weights : 학습이 완료된 weight 파일 경로 (pt 형식) \u003cbr\u003e\n","\u003e\u003e -- conf : IOU_threshold 값 (0 ~ 1 사이의 값)\n"]},{"cell_type":"markdown","metadata":{"id":"XpuLW8yAHN-W"},"source":["* TEST 데이터 다운로드하기(아래의 코드를 실행하세요)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":366,"status":"ok","timestamp":1666589719748,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"Kgxu2agF2cAr","outputId":"22a1c3d8-867a-492c-a09d-2a95b321c85a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# 현재 디렉토리 확인\n","%pwd\n","%cd /content"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3043,"status":"ok","timestamp":1666589723267,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"JnEqBQ8C2MeH","outputId":"ccea4528-3901-46d0-e8cf-2c81d2d8f0ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]-\u003egdown) (1.25.11)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]-\u003egdown) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]-\u003egdown) (2022.9.24)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]-\u003egdown) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,\u003e=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]-\u003egdown) (1.7.1)\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666589723267,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"AcNkxlOD2SYd"},"outputs":[],"source":["import gdown\n","import zipfile"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666589724863,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"ddT3ob9cBZX1"},"outputs":[],"source":["test_file_id = \"14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\"\n","\n","def goolge_drive_download (file_id): \n","  google_path = 'https://drive.google.com/uc?id='\n","  output_name = 'download_file.zip'\n","\n","  gdown.download(google_path+file_id,output_name,quiet=False)\n","\n","  zip_file = \"/content/download_file.zip\"\n","\n","  \n","  with zipfile.ZipFile(zip_file) as z:\n","    z.extractall(\"/content\")\n","\n","  os.remove(zip_file) \n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1724,"status":"ok","timestamp":1666589732044,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"3G3jHfuW2XnO","outputId":"4362285e-02de-4e42-b1ee-3eb1994e3a1b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\n","To: /content/download_file.zip\n","100%|██████████| 9.86M/9.86M [00:00\u003c00:00, 185MB/s]\n"]}],"source":["goolge_drive_download(test_file_id)"]},{"cell_type":"markdown","metadata":{"id":"F4I-AY3bp0Pb"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 9-1. 이미지를 소스로 한 객체 검출하기 \n","\u003e 경로 \"TEST_IMAGE_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","\u003e [조건] \n","\u003e ① img size : 416, ② IOU Threshold : 0.5, ③ 모델 weights : best.pt"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":754,"status":"ok","timestamp":1666589788954,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"av7GzbrdH2HP"},"outputs":[],"source":["# 경로 설정\n","TEST_IMAGE_PATH = \"/content/data/test/images\""]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10658,"status":"ok","timestamp":1666589800097,"user":{"displayName":"이우성","userId":"00926902840550518962"},"user_tz":-540},"id":"J216grQfp0Pb","outputId":"05b2598d-7db8-4c15-ba67-fb10344a428e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt'], source=/content/data/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v6.2-205-geef9057 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/12 /content/data/test/images/test_image_01.jpg: 256x416 (no detections), 19.7ms\n","image 2/12 /content/data/test/images/test_image_02.jpg: 256x416 (no detections), 13.6ms\n","image 3/12 /content/data/test/images/test_image_03.jpg: 256x416 (no detections), 11.2ms\n","image 4/12 /content/data/test/images/test_image_04.jpg: 256x416 (no detections), 8.8ms\n","image 5/12 /content/data/test/images/test_image_05.jpg: 256x416 (no detections), 8.5ms\n","image 6/12 /content/data/test/images/test_image_06.jpg: 256x416 (no detections), 8.1ms\n","image 7/12 /content/data/test/images/test_image_07.jpg: 256x416 (no detections), 8.5ms\n","image 8/12 /content/data/test/images/test_image_08.jpg: 256x416 (no detections), 12.4ms\n","image 9/12 /content/data/test/images/test_image_09.jpg: 256x416 (no detections), 8.6ms\n","image 10/12 /content/data/test/images/test_image_10.jpg: 256x416 (no detections), 8.0ms\n","image 11/12 /content/data/test/images/test_image_11.jpg: 256x416 (no detections), 8.3ms\n","image 12/12 /content/data/test/images/test_image_12.jpg: 256x416 (no detections), 7.4ms\n","Speed: 0.4ms pre-process, 10.3ms inference, 0.4ms NMS per image at shape (1, 3, 416, 416)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}],"source":["# 실습해보세요\n","%cd /content/yolov5\n","\n","!python detect.py --source '{TEST_IMAGE_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5\n"]},{"cell_type":"markdown","metadata":{"id":"7ow6CvdOOLcw"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 9-2. detect가 완료된 이미지를 확인해 보세요.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6VHAuI2I-Rb"},"outputs":[],"source":["# 필요 라이브러리 불러오기\n","from PIL import Image               # to load images\n","from IPython.display import display # to display images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1r0Yr-_uNpzZDArF8TIldG9c8_8VpJzV6"},"id":"_eJlfDx0Bz9S","outputId":"7ca1dc8e-abcb-43dd-b987-cad894478273"},"outputs":[],"source":["# 실습해보세요.\n","detect_image_path = \"/content/yolov5/runs/detect/exp\"  #detect가 완료된 파일의 경로\n","\n","for i in glob.glob(detect_image_path + '/*.jpg'):\n","  img = Image.open(i)\n","  img_resize = img.resize((640, 360))\n","  display(img_resize)\n","  print('\\n')\n"]},{"cell_type":"markdown","metadata":{"id":"u8l3c5namfEs"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 10-1. 동영상을 소스로 한 객체 검출하기 \n","\u003e 경로 \"TEST_VIDEO_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","\u003e [조건] \n","\u003e ① IOU Threshold : 0.5, ② 모델 weights : best.pt "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ0EJ9cnmeKX"},"outputs":[],"source":["# 실습해보세요\n","!python detect.py --source '{TEST_VIDEO_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5"]},{"cell_type":"markdown","metadata":{"id":"bXLmOotHpkjl"},"source":["\u003cfont color=\"green\"\u003e[실습문제]\u003c/font\u003e 10-2. detect가 완료된 동영상을 확인해 보세요.\n","- 아래의 코드는 colab에서 비디오 파일을 실행하기 위해 video 파일을 압축하고 HTML video 속성으로 출력하는 코드입니다. \n","- detect_video(detect가 완료된 비디오 파일) 의 경로만 변경하시고 그대로 실행하시면 되겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTsF2qXVpkIq"},"outputs":[],"source":["# 실습해보세요.\n","detect_video = '/content/test_video_01.mp4' # 경로 수정\n","compressed_video = '' # 압축이 완료된 이후 저장되는 파일 경로 변수\n","\n","# 비디오 데이터 압축 (Colab에서 실행 목적)\n","def video_compressing(detect_video):  \n","  compressed_video = detect_video[:-4] + \"_compressed.mp4\"\n","  os.system(f\"ffmpeg -i {detect_video} -vcodec libx264 {compressed_video}\")\n","\n","  return compressed_video \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1zvHd2sEBPpWgcDB7ckP5-46cobARzj5L"},"id":"LzzZg93a-Zjn","outputId":"1533afd1-8da5-42f6-bb4c-ebd45d0df269"},"outputs":[],"source":["compressed_video = video_compressing(detect_video)\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","mp4 = open(compressed_video,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","\u003cvideo width=400 controls\u003e\n","    \u003csource src=\"%s\" type=\"video/mp4\"\u003e\n","\u003c/video\u003e\n","\"\"\" % data_url)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}